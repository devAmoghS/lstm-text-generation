# lstm-text-generation
A generative model for text, character-by-character using LSTM recurrent neural networks in Python with Keras. Later extending to make a Predictive Keyboard Application on Android.

# Data
The corpus is adopted from Alice’s Adventures in Wonderland by Lewis Carroll (Project Gutenberg).

# Files

`small_network.py` - used to train the model and generate weights, which are saved at every epoch.

`load_network.py` - used to generate the text when the weights are loaded.

# Sample:

## Seed:
" written down: but i can’t quite follow it as you say it.’

## Generated Text (for epoch:20, loss:1.7064)
‘that’s nothing to what i could say if i  "
cen ’our majesty,’ said alice, ‘i whnh toee oo that would be a lotee of thet is oakser!’ 
‘i don’t know what a dat oi a can oi toer ’ shought alice, ‘i don’t see at that io the same thing is to ba a torn of thet witl she tay of the courd be iuse totnd her an tee could, oo thet tam the wailed off to het oo the same way wou fane and a large handene of the saye toine of the say of the cane with her haad oo the wall as it lad an oede, 
‘hf io was a latter al a seae ther,’ said the cat, ‘i dan doeny to lake derner ’ou say then i saek to meke oi the same thilg as yhu ai i theng ’

‘ho i soed to tey it in,’ said alice as the could. 
‘toen of toem ’ shouted the queen. 
‘if io was ao all moce,’ said alice, ‘i whnt to the same thing is that you cave tall to meke that io was ao oede oi the same thing as yhu as she master with a latce hardeners, and when the was not tuiek to be a lotse of the sabbe, hu was aol more to ba a pealen he then so be a letten of the saye thing whel they were the case an 
